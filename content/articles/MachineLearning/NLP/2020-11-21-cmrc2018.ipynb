{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- date: 2020-11-21 10:17:17\n",
    "- author: Jerry Su\n",
    "- slug: cmrc2018-dataset\n",
    "- title: cmrc2018 dataset\n",
    "- category: \n",
    "- tags: Deep Learning, TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /root/anaconda3/envs/torch/lib/python3.7/site-packages (1.1.2)\n",
      "Requirement already satisfied: pyarrow>=0.17.1 in /root/anaconda3/envs/torch/lib/python3.7/site-packages (from datasets) (2.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /root/anaconda3/envs/torch/lib/python3.7/site-packages (from datasets) (2.24.0)\n",
      "Requirement already satisfied: dill in /root/anaconda3/envs/torch/lib/python3.7/site-packages (from datasets) (0.3.3)\n",
      "Requirement already satisfied: xxhash in /root/anaconda3/envs/torch/lib/python3.7/site-packages (from datasets) (2.0.0)\n",
      "Requirement already satisfied: multiprocess in /root/anaconda3/envs/torch/lib/python3.7/site-packages (from datasets) (0.70.11.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/anaconda3/envs/torch/lib/python3.7/site-packages (from datasets) (1.18.5)\n",
      "Requirement already satisfied: pandas in /root/anaconda3/envs/torch/lib/python3.7/site-packages (from datasets) (1.1.4)\n",
      "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /root/anaconda3/envs/torch/lib/python3.7/site-packages (from datasets) (4.28.1)\n",
      "Requirement already satisfied: filelock in /root/anaconda3/envs/torch/lib/python3.7/site-packages (from datasets) (3.0.12)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /root/anaconda3/envs/torch/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/anaconda3/envs/torch/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /root/anaconda3/envs/torch/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /root/anaconda3/envs/torch/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: pytz>=2017.2 in /root/anaconda3/envs/torch/lib/python3.7/site-packages (from pandas->datasets) (2020.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /root/anaconda3/envs/torch/lib/python3.7/site-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /root/anaconda3/envs/torch/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import list_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_list = list_datasets()\n",
    "len(datasets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fraser/news-category-dataset, aeslc, ag_news, ai2_arc, allocine, amazon_us_reviews, anli, arcd, art, aslg_pc12, asnq, billsum, biomrc, blended_skill_talk, blimp, blog_authorship_corpus, bookcorpus, bookcorpusopen, boolq, break_data, c4, cdminix/mgb1, cfq, civil_comments, clue, cmrc2018, cnn_dailymail, coarse_discourse, com_qa, common_gen, commonsense_qa, compguesswhat, conll2000, conll2003, coqa, cornell_movie_dialog, cos_e, cosmos_qa, crd3, crime_and_punish, csv, daily_dialog, definite_pronoun_resolution, discofuse, docred, doqa, drop, eli5, emo, emotion, empathetic_dialogues, eraser_multi_rc, esnli, event2Mind, fever, flores, fquad, gap, germeval_14, gigaword, glue, guardian_authorship, hans, hansards, hellaswag, hotpot_qa, hyperpartisan_news_detection, imdb, iwslt2017, jeopardy, joelito/sem_eval_2010_task_8, json, kilt_tasks, kilt_wikipedia, kor_nli, lc_quad, lhoestq/squad, librispeech_lm, lince, lm1b, math_dataset, math_qa, matinf, mlqa, mlsum, movie_rationales, ms_marco, multi_news, multi_nli, multi_nli_mismatch, mwsc, natural_questions, newsgroup, newsroom, nli_tr, openbookqa, openwebtext, opinosis, pandas, para_crawl, pg19, piEsposito/br-quad-2.0, piEsposito/br_quad_20, piEsposito/squad_20_ptbr, piaf, polyglot_ner, qa4mre, qa_zre, qangaroo, qanta, qasc, quail, quarel, quartz, quora, quoref, race, reclor, reddit, reddit_tifu, reuters21578, rotten_tomatoes, scan, scicite, scientific_papers, scifact, sciq, scitail, search_qa, sentiment140, snli, social_bias_frames, social_i_qa, sogou_news, squad, squad_es, squad_it, squad_v1_pt, squad_v2, squadshifts, sshleifer/pseudo_bart_xsum, style_change_detection, super_glue, ted_hrlr, ted_multi, text, tiny_shakespeare, trec, trivia_qa, tydiqa, ubuntu_dialogs_corpus, web_of_science, web_questions, wiki40b, wiki_dpr, wiki_qa, wiki_snippets, wiki_split, wikihow, wikipedia, wikisql, wikitext, winogrande, wiqa, wmt14, wmt15, wmt16, wmt17, wmt18, wmt19, wmt_t2t, wnut_17, x_stance, xcopa, xnli, xquad, xsum, xtreme, yelp_polarity'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = [dataset for dataset in datasets_list]\n",
    "', '.join(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset cmrc2018 (./cmrc2018/default/0.1.0/c7b7e6267a94990b52713c35eb1ba91c18265524d7fe7317a85e6e1b1b85cc8f)\n"
     ]
    }
   ],
   "source": [
    "train_cmrc, test_cmrc = load_dataset('cmrc2018',cache_dir='./' , split=['train', 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(features: {'id': Value(dtype='string', id=None), 'context': Value(dtype='string', id=None), 'question': Value(dtype='string', id=None), 'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None)}, num_rows: 10142)\n"
     ]
    }
   ],
   "source": [
    "print(train_cmrc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answers': [{'answer_start': [122], 'text': ['JR东日本所属的月台区是位于车站二楼']},\n",
       "  {'answer_start': [369], 'text': ['1998年3月29日由地面车站改建为高架车站。']},\n",
       "  {'answer_start': [10], 'text': ['日本长野县上田市天神1丁目']},\n",
       "  {'answer_start': [166], 'text': ['检票口皆位于二楼的桥上站屋内']},\n",
       "  {'answer_start': [158],\n",
       "   'text': ['凤凰卫视资讯台会在每晚20点档《凤凰正点播报》开始前播放国歌，播放版本与香港电视台主流频道一致']},\n",
       "  {'answer_start': [108], 'text': ['凤凰卫视资讯台于2013年开播高清版，此时标清版为切边播出。']},\n",
       "  {'answer_start': [356],\n",
       "   'text': ['该服务一般提供给中国境内三星级或以上的涉外宾馆酒店、外国人居住区、领事馆及大使馆。']},\n",
       "  {'answer_start': [336], 'text': ['繁殖期约为7月至翌年2月']},\n",
       "  {'answer_start': [375], 'text': ['半领彩鹬是在智利及阿根廷等地是民间传统上的赛鸟，因此多有被捕猎的纪录。']},\n",
       "  {'answer_start': [447],\n",
       "   'text': ['但到目前为止，仍未有文献指其种群数目有太大的威胁，因此在IUCN红色名录内评为无危物种。']}],\n",
       " 'context': ['上田车站（）是一位于日本长野县上田市天神1丁目，由东日本旅客铁道（JR东日本）、信浓铁道（）与上田电铁所共用的铁路车站。上田车站是JR东日本所经营的北陆新干线与两条地方铁路线信浓铁道线（）与上田电铁别所线之交会车站。配合全面高架化的新干线路线，JR东日本所属的月台区是位于车站二楼（但检票口位于一楼），至于信浓铁道与上田电铁的部分，检票口皆位于二楼的桥上站屋内，但月台与铁路线则分别设置于二楼（信浓铁道线）与一楼（别所线）处。对向式月台2面2线的高架车站。。是北陆新干线轻井泽至长野段唯一的高架车站。由于不设待避线，因此设有月台闸门。起初计划为岛式2面4线，但根据通车后的需求预测轻井泽与长野之间不需要待避设备，成为现时对向式月台2面2线。对向式月台（下行本线）与岛式月台（中线与上行本线）2面3线的地面车站。侧式月台1面1线的高架车站。1998年3月29日由地面车站改建为高架车站。',\n",
       "  '上田车站（）是一位于日本长野县上田市天神1丁目，由东日本旅客铁道（JR东日本）、信浓铁道（）与上田电铁所共用的铁路车站。上田车站是JR东日本所经营的北陆新干线与两条地方铁路线信浓铁道线（）与上田电铁别所线之交会车站。配合全面高架化的新干线路线，JR东日本所属的月台区是位于车站二楼（但检票口位于一楼），至于信浓铁道与上田电铁的部分，检票口皆位于二楼的桥上站屋内，但月台与铁路线则分别设置于二楼（信浓铁道线）与一楼（别所线）处。对向式月台2面2线的高架车站。。是北陆新干线轻井泽至长野段唯一的高架车站。由于不设待避线，因此设有月台闸门。起初计划为岛式2面4线，但根据通车后的需求预测轻井泽与长野之间不需要待避设备，成为现时对向式月台2面2线。对向式月台（下行本线）与岛式月台（中线与上行本线）2面3线的地面车站。侧式月台1面1线的高架车站。1998年3月29日由地面车站改建为高架车站。',\n",
       "  '上田车站（）是一位于日本长野县上田市天神1丁目，由东日本旅客铁道（JR东日本）、信浓铁道（）与上田电铁所共用的铁路车站。上田车站是JR东日本所经营的北陆新干线与两条地方铁路线信浓铁道线（）与上田电铁别所线之交会车站。配合全面高架化的新干线路线，JR东日本所属的月台区是位于车站二楼（但检票口位于一楼），至于信浓铁道与上田电铁的部分，检票口皆位于二楼的桥上站屋内，但月台与铁路线则分别设置于二楼（信浓铁道线）与一楼（别所线）处。对向式月台2面2线的高架车站。。是北陆新干线轻井泽至长野段唯一的高架车站。由于不设待避线，因此设有月台闸门。起初计划为岛式2面4线，但根据通车后的需求预测轻井泽与长野之间不需要待避设备，成为现时对向式月台2面2线。对向式月台（下行本线）与岛式月台（中线与上行本线）2面3线的地面车站。侧式月台1面1线的高架车站。1998年3月29日由地面车站改建为高架车站。',\n",
       "  '上田车站（）是一位于日本长野县上田市天神1丁目，由东日本旅客铁道（JR东日本）、信浓铁道（）与上田电铁所共用的铁路车站。上田车站是JR东日本所经营的北陆新干线与两条地方铁路线信浓铁道线（）与上田电铁别所线之交会车站。配合全面高架化的新干线路线，JR东日本所属的月台区是位于车站二楼（但检票口位于一楼），至于信浓铁道与上田电铁的部分，检票口皆位于二楼的桥上站屋内，但月台与铁路线则分别设置于二楼（信浓铁道线）与一楼（别所线）处。对向式月台2面2线的高架车站。。是北陆新干线轻井泽至长野段唯一的高架车站。由于不设待避线，因此设有月台闸门。起初计划为岛式2面4线，但根据通车后的需求预测轻井泽与长野之间不需要待避设备，成为现时对向式月台2面2线。对向式月台（下行本线）与岛式月台（中线与上行本线）2面3线的地面车站。侧式月台1面1线的高架车站。1998年3月29日由地面车站改建为高架车站。',\n",
       "  '凤凰卫视资讯台于2001年1月1日正式开播，是凤凰卫视全日24小时播放来自全球各地时事新闻与财经资讯的频道。重点在两岸以至全球华人地区的新闻资讯报道及评论，2003年在中国大陆落地。而广东有线仅有中文台，没有资讯台。凤凰卫视资讯台于2013年开播高清版，此时标清版为切边播出。2014年起开始标清16:9播出。另外，凤凰卫视资讯台会在每晚20点档《凤凰正点播报》开始前播放国歌，播放版本与香港电视台主流频道一致。凤凰卫视资讯台于亚洲3号S卫星通过C波段向整个亚洲、澳洲及非洲北部广播，以数码制式的DVB-S调制及MPEG-2编码，香港部分大厦使用卫星电视共用天线系统将讯号转为PAL制式模拟信号供住户收看。中国国际电视总公司境外卫星代理部接收凤凰卫视资讯台信号，通过亚太6号卫星（东经134度）发射KU波段信号。该服务一般提供给中国境内三星级或以上的涉外宾馆酒店、外国人居住区、领事馆及大使馆。部分中国城市更可以在有线电视上免费或额外付费观看。注：部分记者会兼以粤语于香港台作报导。',\n",
       "  '凤凰卫视资讯台于2001年1月1日正式开播，是凤凰卫视全日24小时播放来自全球各地时事新闻与财经资讯的频道。重点在两岸以至全球华人地区的新闻资讯报道及评论，2003年在中国大陆落地。而广东有线仅有中文台，没有资讯台。凤凰卫视资讯台于2013年开播高清版，此时标清版为切边播出。2014年起开始标清16:9播出。另外，凤凰卫视资讯台会在每晚20点档《凤凰正点播报》开始前播放国歌，播放版本与香港电视台主流频道一致。凤凰卫视资讯台于亚洲3号S卫星通过C波段向整个亚洲、澳洲及非洲北部广播，以数码制式的DVB-S调制及MPEG-2编码，香港部分大厦使用卫星电视共用天线系统将讯号转为PAL制式模拟信号供住户收看。中国国际电视总公司境外卫星代理部接收凤凰卫视资讯台信号，通过亚太6号卫星（东经134度）发射KU波段信号。该服务一般提供给中国境内三星级或以上的涉外宾馆酒店、外国人居住区、领事馆及大使馆。部分中国城市更可以在有线电视上免费或额外付费观看。注：部分记者会兼以粤语于香港台作报导。',\n",
       "  '凤凰卫视资讯台于2001年1月1日正式开播，是凤凰卫视全日24小时播放来自全球各地时事新闻与财经资讯的频道。重点在两岸以至全球华人地区的新闻资讯报道及评论，2003年在中国大陆落地。而广东有线仅有中文台，没有资讯台。凤凰卫视资讯台于2013年开播高清版，此时标清版为切边播出。2014年起开始标清16:9播出。另外，凤凰卫视资讯台会在每晚20点档《凤凰正点播报》开始前播放国歌，播放版本与香港电视台主流频道一致。凤凰卫视资讯台于亚洲3号S卫星通过C波段向整个亚洲、澳洲及非洲北部广播，以数码制式的DVB-S调制及MPEG-2编码，香港部分大厦使用卫星电视共用天线系统将讯号转为PAL制式模拟信号供住户收看。中国国际电视总公司境外卫星代理部接收凤凰卫视资讯台信号，通过亚太6号卫星（东经134度）发射KU波段信号。该服务一般提供给中国境内三星级或以上的涉外宾馆酒店、外国人居住区、领事馆及大使馆。部分中国城市更可以在有线电视上免费或额外付费观看。注：部分记者会兼以粤语于香港台作报导。',\n",
       "  '半领彩鹬（学名：\\'）是一种涉禽，属于鸟纲鸻形目彩鹬科，是半领彩鹬属\"\\'下的单属种。其所属的彩鹬科（\"Rostratulidae\"）也是一个小科，只有另一属另外两个物种。头及颈为深红棕色并在鸟冠上带有黄色条纹，上半身深灰棕色配白点；下半身全白。此科的雌鸟一般体型较大及毛色较亮丽，但此种对比起另外两种，两性异形的情况并不明显。有一相对较长及笔直的喙部，趾上有蹼等特征都使此种与另外两种区为不同的属。体长19至23厘米，重65至86克。此种分布于南美洲的南部，包括巴西南部、巴拿圭、乌拉圭、智利及阿根廷等地，生境为低地区的淡水湿地及湿润草原等。杂食性，于黄昏时间探头于湿润的泥中吞食无脊椎动物及种子等。一夫一妻制，筑巢于湿地旁不起眼的草丛中，浅薄的半盖状，一丛约生2至3枚蛋。繁殖期约为7月至翌年2月。沙哑叫声，在饲养种中曾录得\"wee-oo\"般的低呜。半领彩鹬是在智利及阿根廷等地是民间传统上的赛鸟，因此多有被捕猎的纪录。在其广泛分布的区域内并不是一种常见鸟种，淡水湿地也而受到被抽干池水的威胁。但到目前为止，仍未有文献指其种群数目有太大的威胁，因此在IUCN红色名录内评为无危物种。',\n",
       "  '半领彩鹬（学名：\\'）是一种涉禽，属于鸟纲鸻形目彩鹬科，是半领彩鹬属\"\\'下的单属种。其所属的彩鹬科（\"Rostratulidae\"）也是一个小科，只有另一属另外两个物种。头及颈为深红棕色并在鸟冠上带有黄色条纹，上半身深灰棕色配白点；下半身全白。此科的雌鸟一般体型较大及毛色较亮丽，但此种对比起另外两种，两性异形的情况并不明显。有一相对较长及笔直的喙部，趾上有蹼等特征都使此种与另外两种区为不同的属。体长19至23厘米，重65至86克。此种分布于南美洲的南部，包括巴西南部、巴拿圭、乌拉圭、智利及阿根廷等地，生境为低地区的淡水湿地及湿润草原等。杂食性，于黄昏时间探头于湿润的泥中吞食无脊椎动物及种子等。一夫一妻制，筑巢于湿地旁不起眼的草丛中，浅薄的半盖状，一丛约生2至3枚蛋。繁殖期约为7月至翌年2月。沙哑叫声，在饲养种中曾录得\"wee-oo\"般的低呜。半领彩鹬是在智利及阿根廷等地是民间传统上的赛鸟，因此多有被捕猎的纪录。在其广泛分布的区域内并不是一种常见鸟种，淡水湿地也而受到被抽干池水的威胁。但到目前为止，仍未有文献指其种群数目有太大的威胁，因此在IUCN红色名录内评为无危物种。',\n",
       "  '半领彩鹬（学名：\\'）是一种涉禽，属于鸟纲鸻形目彩鹬科，是半领彩鹬属\"\\'下的单属种。其所属的彩鹬科（\"Rostratulidae\"）也是一个小科，只有另一属另外两个物种。头及颈为深红棕色并在鸟冠上带有黄色条纹，上半身深灰棕色配白点；下半身全白。此科的雌鸟一般体型较大及毛色较亮丽，但此种对比起另外两种，两性异形的情况并不明显。有一相对较长及笔直的喙部，趾上有蹼等特征都使此种与另外两种区为不同的属。体长19至23厘米，重65至86克。此种分布于南美洲的南部，包括巴西南部、巴拿圭、乌拉圭、智利及阿根廷等地，生境为低地区的淡水湿地及湿润草原等。杂食性，于黄昏时间探头于湿润的泥中吞食无脊椎动物及种子等。一夫一妻制，筑巢于湿地旁不起眼的草丛中，浅薄的半盖状，一丛约生2至3枚蛋。繁殖期约为7月至翌年2月。沙哑叫声，在饲养种中曾录得\"wee-oo\"般的低呜。半领彩鹬是在智利及阿根廷等地是民间传统上的赛鸟，因此多有被捕猎的纪录。在其广泛分布的区域内并不是一种常见鸟种，淡水湿地也而受到被抽干池水的威胁。但到目前为止，仍未有文献指其种群数目有太大的威胁，因此在IUCN红色名录内评为无危物种。'],\n",
       " 'id': ['TRAIN_325_QUERY_1',\n",
       "  'TRAIN_325_QUERY_2',\n",
       "  'TRAIN_325_QUERY_3',\n",
       "  'TRAIN_325_QUERY_4',\n",
       "  'TRAIN_5_QUERY_0',\n",
       "  'TRAIN_5_QUERY_1',\n",
       "  'TRAIN_5_QUERY_2',\n",
       "  'TRAIN_169_QUERY_0',\n",
       "  'TRAIN_169_QUERY_1',\n",
       "  'TRAIN_169_QUERY_2'],\n",
       " 'question': ['JR东日本所属的月台区在哪里？',\n",
       "  '由地面车站改为高架车站是在什么时候？',\n",
       "  '上田车站在日本的哪个地方？',\n",
       "  '信浓铁道与上田电铁的检票口在哪里？',\n",
       "  '凤凰卫视资讯台与香港电视台主流频道保持一致，体现在哪？',\n",
       "  '2013年，凤凰卫视资讯台有什么变化？',\n",
       "  '通过亚太6号卫星发射的信号，其服务对象是？',\n",
       "  '半领彩鹬的繁殖期是什么时候？',\n",
       "  '半领彩鹬常被捕猎的原因是什么？',\n",
       "  '为什么此鸟被评为无危物种？']}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 500\n",
    "train_cmrc[x:x+10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('hfl/chinese-bert-wwm-ext') #, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(1, 100), dtype=int32, numpy=\n",
       "array([[ 101, 5745, 2455, 7563, 3221,  754,  862, 3198,  862, 1765, 1139,\n",
       "        4495, 4638, 8043,  102, 5745, 2455, 7563, 3364, 3322, 8020, 8024,\n",
       "        8021, 8024, 1760, 1399,  924, 4882,  185, 5735, 4449, 8020, 8021,\n",
       "        8024, 3221, 6632, 1298, 5384, 7716, 1921,  712, 3136, 3364, 3322,\n",
       "         511, 9155, 2399, 6158,  818,  711,  712, 3136, 8039, 8431, 2399,\n",
       "        6158, 3091, 1285,  711, 1921,  712, 3136, 3777, 1079, 2600, 3136,\n",
       "        1277, 2134, 2429, 5392, 4415, 8039, 8447, 2399, 6158, 3091, 1285,\n",
       "         711, 2600,  712, 3136, 8024, 1398, 2399, 2399, 2419, 6158, 3091,\n",
       "        1285,  711, 3364, 3322, 8039, 8170, 2399,  123, 3299, 4895,  686,\n",
       "         102]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(1, 100), dtype=int32, numpy=\n",
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 100), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(text=train_cmrc[2]['question'],\n",
    "                   text_pair=train_cmrc[2]['context'],\n",
    "                   truncation='only_second',\n",
    "                   padding='max_length',\n",
    "                   max_length=100,\n",
    "                   return_tensors='tf')\n",
    "#inputs['start_position'] = train_cmrc[2]['answers']['answer_start'][0]\n",
    "#inputs['end_position'] = inputs['start_position'] + len(train_cmrc[2]['answers']['text'][0]) - 1\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(instance):\n",
    "    inputs_dict = tokenizer(text=instance['question'],\n",
    "                            text_pair=instance['context'],\n",
    "                            truncation='only_second',\n",
    "                            padding='max_length',\n",
    "                            max_length=512)\n",
    "    inputs_dict['start_position'] = instance['answers']['answer_start'][0]\n",
    "    inputs_dict['end_position'] = inputs_dict['start_position'] + len(instance['answers']['text'][0]) - 1\n",
    "    return inputs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72f0dfa4f61f4d3f88b76011e9402636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10142), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8233dbc693024ecca79b581d49e66790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1002), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = train_cmrc.map(encode)\n",
    "test = test_cmrc.map(encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10142 1002\n"
     ]
    }
   ],
   "source": [
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'start_position', 'end_position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(train, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'end_position': tensor([ 34,  61, 125, 597, 779,  41, 253, 725, 204,  86, 195, 460,  44,  95,\n",
       "         125, 221, 369,  69,  90, 193, 435, 498,  13, 134, 287, 227, 247, 335,\n",
       "          17,  61,  22,  30]),\n",
       " 'input_ids': tensor([[ 101, 5745, 2455,  ..., 2429, 5392,  102],\n",
       "         [ 101, 8431, 2399,  ..., 4415,  809,  102],\n",
       "         [ 101, 5745, 2455,  ..., 4415,  809,  102],\n",
       "         ...,\n",
       "         [ 101, 7942, 4324,  ...,    0,    0,    0],\n",
       "         [ 101,  784,  720,  ...,    0,    0,    0],\n",
       "         [ 101, 1762, 4179,  ...,    0,    0,    0]]),\n",
       " 'start_position': tensor([ 30,  41,  97, 548, 759,  26, 247, 706, 202,  84, 156, 391,  27,  88,\n",
       "         108, 213, 267,  61,  86, 185, 397, 463,  11, 126, 237, 150, 229, 320,\n",
       "           0,  57,   0,  23]),\n",
       " 'token_type_ids': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:blog] *",
   "language": "python",
   "name": "conda-env-blog-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
